{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: \n",
    "This is the notebook where we performed experiments on the object detection model.\n",
    "All of the outputs were cleared in order to cut down on the length of the notebook\n",
    "The model loading and data preparation is credits to Daniel Bourke's amenity detection project: \n",
    "https://towardsdatascience.com/replicating-airbnbs-amenity-detection-with-detectron2-28f33704d6ff\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "import os\n",
    "setup_logger() \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2 import model_zoo \n",
    "from detectron2.engine import DefaultPredictor \n",
    "from detectron2.config import get_cfg \n",
    "from detectron2.utils.visualizer import Visualizer \n",
    "from detectron2.data import MetadataCatalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = ['Bathtub',\n",
    " 'Bed',\n",
    " 'Billiard table',\n",
    " 'Ceiling fan',\n",
    " 'Coffeemaker',\n",
    " 'Couch',\n",
    " 'Countertop',\n",
    " 'Dishwasher',\n",
    " 'Fireplace',\n",
    " 'Fountain',\n",
    " 'Gas stove',\n",
    " 'Jacuzzi',\n",
    " 'Kitchen & dining room table',\n",
    " 'Microwave oven',\n",
    " 'Mirror',\n",
    " 'Oven',\n",
    " 'Pillow',\n",
    " 'Porch',\n",
    " 'Refrigerator',\n",
    " 'Shower',\n",
    " 'Sink',\n",
    " 'Sofa bed',\n",
    " 'Stairs',\n",
    " 'Swimming pool',\n",
    " 'Television',\n",
    " 'Toilet',\n",
    " 'Towel',\n",
    " 'Tree house',\n",
    " 'Washing machine',\n",
    " 'Wine rack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_cfg = get_cfg() \n",
    "pt_cfg.merge_from_file(\"./retinanet_model_final_config.yaml\") \n",
    "pt_cfg.MODEL.WEIGHTS = \"./retinanet_model_final.pth\" \n",
    "pt_predictor = DefaultPredictor(pt_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./train/\"\n",
    "valid_path = \"./validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_ids(image_folder=None):\n",
    "    return [os.path.splitext(img_name)[0] for img_name in os.listdir(image_folder) if img_name.endswith(\".jpg\")]\n",
    "val_img_ids = get_image_ids(valid_path)\n",
    "val_annots = pd.read_csv(\"validation-annotations-bbox.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_annotations(image_folder, annotation_file, target_classes=None):\n",
    "    Formats annotation_file based on images contained in image_folder.\n",
    "    Will get all unique image IDs and \n",
    "    image_ids = get_image_ids(image_folder)\n",
    "    annot_file = pd.read_csv(annotation_file)\n",
    "    classes = pd.read_csv(\"class-descriptions-boxable.csv\",\n",
    "                          names=[\"LabelName\", \"ClassName\"])\n",
    "    annot_file[\"ClassName\"] = annot_file[\"LabelName\"].map(classes.set_index(\"LabelName\")[\"ClassName\"])\n",
    "    annot_file.sort_values(by=[\"ClassName\"], inplace=True)\n",
    "    if target_classes:\n",
    "        annot_file = annot_file[annot_file[\"ImageID\"].isin(image_ids) & annot_file[\"ClassName\"].isin(target_classes)]\n",
    "    else:\n",
    "        annot_file = annot_file[annot_file[\"ImageID\"].isin(image_ids)]\n",
    "    assert len(annot_file.ImageID.unique()) == len(image_ids), \"Label unique ImageIDs doesn't match target folder.\"\n",
    "    annot_file[\"ClassName\"] = pd.Categorical(annot_file[\"ClassName\"])\n",
    "    annot_file[\"ClassID\"] = annot_file[\"ClassName\"].cat.codes\n",
    "    \n",
    "    return annot_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_annots_formatted = format_annotations(image_folder=valid_path,\n",
    "                                          annotation_file=\"validation-annotations-bbox.csv\",\n",
    "                                          target_classes=target_classes) # (fireplace & coffeemaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_to_absolute(bbox, height, width):\n",
    "    bbox[0] = np.round(np.multiply(bbox[0], width)) # x0\n",
    "    bbox[1] = np.round(np.multiply(bbox[1], height)) # y0\n",
    "    bbox[2] = np.round(np.multiply(bbox[2], width)) # x1\n",
    "    bbox[3] = np.round(np.multiply(bbox[3], height)) # y1\n",
    "    return [i.astype(\"object\") for i in bbox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import BoxMode\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "def get_image_dicts(image_folder, annotation_file, target_classes=None):\n",
    "    dataset_name = str(image_folder)\n",
    "    annotations = format_annotations(image_folder=image_folder, \n",
    "                                     annotation_file=annotation_file,\n",
    "                                     target_classes=target_classes)\n",
    "    img_ids = get_image_ids(image_folder)\n",
    "    print(f\"\\nUsing {annotation_file} for annotations...\")\n",
    "    print(f\"On dataset: {dataset_name}\")\n",
    "    print(\"Classes we're using:\\n{}\".format(annotations[\"ClassName\"].value_counts()))\n",
    "    print(f\"Total number of images: {len(img_ids)}\")\n",
    "    img_dicts = []\n",
    "    for idx, img in tqdm(enumerate(img_ids)):\n",
    "        record = {}\n",
    "        file_name = image_folder + img + \".jpg\"\n",
    "        height, width = cv2.imread(file_name).shape[:2]\n",
    "        img_data = annotations[annotations[\"ImageID\"] == img].reset_index()\n",
    "        record[\"file_name\"] = file_name\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        img_annotations = []\n",
    "        for i in range(len(img_data)): \n",
    "            category_id = img_data.loc[i][\"ClassID\"].astype(\"object\") \n",
    "            bbox = np.float32(img_data.loc[i][[\"XMin\", \"YMin\", \"XMax\", \"YMax\"]].values)\n",
    "            bbox = rel_to_absolute(bbox=bbox, height=height, width=width)\n",
    "            annot = {\n",
    "                \"bbox\": bbox, \n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS, \n",
    "                \"category_id\": category_id\n",
    "            }\n",
    "            img_annotations.append(annot)\n",
    "        record[\"annotations\"] = img_annotations\n",
    "        img_dicts.append(record)\n",
    "    prefix = \"valid\" if \"valid\" in image_folder else \"train\"\n",
    "    json_file = os.path.join(image_folder, prefix + \"_labels.json\")\n",
    "    print(f\"\\nSaving labels to: {json_file}...\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "      json.dump(img_dicts, f)\n",
    "    print(\"Showing an example:\")\n",
    "    pprint.pprint(random.sample(img_dicts, 1))\n",
    "    return img_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_dicts = get_image_dicts(image_folder=valid_path,\n",
    "                                annotation_file=\"validation-annotations-bbox.csv\",\n",
    "                                target_classes=target_classes)\n",
    "train_img_dicts = get_image_dicts(image_folder=train_path,\n",
    "                                  annotation_file=\"train-annotations-bbox.csv\",\n",
    "                                  target_classes=target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_labels(image_folder):\n",
    "    for file in os.listdir(image_folder):\n",
    "      if file.endswith(\".json\"):\n",
    "        json_file = os.path.join(image_folder, file) \n",
    "    assert json_file, \"No .json label file found, please make one with get_image_dicts()\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "      img_dicts = json.load(f)\n",
    "    for img_dict in img_dicts:\n",
    "      for annot in img_dict[\"annotations\"]:\n",
    "        annot[\"bbox_mode\"] = BoxMode.XYXY_ABS\n",
    "    return img_dicts\n",
    "loaded_val_img_dicts = load_json_labels(valid_path)\n",
    "loaded_train_img_dicts = load_json_labels(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_path = './aug/'\n",
    "loaded_aug_img_dicts = load_json_labels(aug_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "for dataset in [\"train\", \"validation\"]:\n",
    "    dataset_name = dataset\n",
    "    print(f\"Registering {dataset_name}\")\n",
    "    DatasetCatalog.register(dataset_name, lambda dataset_name=dataset_name: load_json_labels(dataset_name))\n",
    "    MetadataCatalog.get(dataset_name).set(thing_classes=target_classes)\n",
    "metadata = MetadataCatalog.get(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2 \n",
    "pt_cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "pt_cfg.MODEL.RETINANET.NUM_CLASSES = len(target_classes)\n",
    "pt_cfg.DATASETS.TEST = (\"validation\",) \n",
    "pt_predictor = DefaultPredictor(pt_cfg)\n",
    "pt_trainer = DefaultTrainer(pt_cfg)\n",
    "pt_trainer.resume_or_load(resume=False) \n",
    "pt_evaluator = COCOEvaluator(dataset_name=\"validation\", \n",
    "                          cfg=pt_cfg, \n",
    "                          distributed=False,\n",
    "                          output_dir=\"./output_pt/\")\n",
    "pt_val_loader = build_detection_test_loader(pt_cfg, \n",
    "                                         dataset_name=\"validation\")\n",
    "inference_on_dataset(model=pt_trainer.model, \n",
    "                     data_loader=pt_val_loader, \n",
    "                     evaluator=pt_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/config.yaml\", \"w\") as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference(image, model_config, model_weights, threshold=0.5, n=5):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_config)\n",
    "    cfg.MODEL.WEIGHTS = model_weights\n",
    "    cfg.MODEL.SCORE_THRESH_TEST = threshold\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    img = cv2.imread(image)\n",
    "    visualizer = Visualizer(img_rgb=img[:, :, ::-1],\n",
    "                          metadata=MetadataCatalog.get(cfg.DATASETS.TEST[0]),\n",
    "                          scale=0.7)\n",
    "\n",
    "    outputs = predictor(img) \n",
    "#     print(outputs[\"instances\"][:n])\n",
    "    visualizer = visualizer.draw_instance_predictions(outputs[\"instances\"][:n].to(\"cpu\"))\n",
    "    #     cv2_imshow(visualizer.get_image()[:, :, ::-1])\n",
    "    pred_image = visualizer.get_image()[:, :, ::-1]\n",
    "    plt.figure(figsize = (20,20))\n",
    "    plt.imshow(pred_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "num_occ = Counter([val_img_dicts[i]['annotations'][j]['category_id'] for i in range(len(val_img_dicts)) for j in range(len(val_img_dicts[i]['annotations']))])\n",
    "print(num_occ)\n",
    "print(val_img_dicts[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_img_dicts)):\n",
    "    for j in range(len(val_img_dicts[i]['annotations'])):\n",
    "        if val_img_dicts[i]['annotations'][j]['category_id'] == 19:\n",
    "            print(val_img_dicts[i]['width'])\n",
    "            print(val_img_dicts[i]['height'])\n",
    "            print(val_img_dicts[i]['annotations'])\n",
    "            make_inference(val_img_dicts[i]['file_name'],\n",
    "               model_config=\"retinanet_model_final_config.yaml\",\n",
    "               model_weights=\"retinanet_model_final.pth\",\n",
    "               n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swimming pool                  161\n",
    "# Bed                            125\n",
    "# Pillow                          76\n",
    "# Kitchen & dining room table     76\n",
    "# Countertop                      68\n",
    "# Sofa bed                        61\n",
    "# Couch                           61\n",
    "# Sink                            57\n",
    "# Porch                           52\n",
    "# Stairs                          45\n",
    "# Television                      44\n",
    "# Fireplace                       41\n",
    "# Washing machine                 40\n",
    "# Toilet                          37\n",
    "# Oven                            36\n",
    "# Mirror                          33\n",
    "# Billiard table                  32\n",
    "# Microwave oven                  30\n",
    "# Refrigerator                    26\n",
    "# Fountain                        24\n",
    "# Gas stove                       23\n",
    "# Coffeemaker                     21\n",
    "# Bathtub                         18\n",
    "# Wine rack                       17\n",
    "# Jacuzzi                         16\n",
    "# Tree house                      11\n",
    "# Ceiling fan                     11\n",
    "# Shower                           9\n",
    "# Towel                            9\n",
    "# Dishwasher                       3\n",
    "\n",
    "\n",
    "str_to_id = {\"Swimming pool\":                 23,\n",
    "\"Bed\":                            1,\n",
    "\"Pillow\":                          16,\n",
    "\"Kitchen & dining room table\":     12,\n",
    "\"Countertop\":                      6,\n",
    "\"Sofa bed\":                        21,\n",
    "\"Couch\":                           5,\n",
    "\"Sink\":                            20,\n",
    "\"Porch\":                           17,\n",
    "\"Stairs\":                          22,\n",
    "\"Television\":                      24,\n",
    "\"Fireplace\":                       8,\n",
    "\"Washing machine\":                 28,\n",
    "\"Toilet\":                          25,\n",
    "\"Oven\":                            15,\n",
    "\"Mirror\":                          14,\n",
    "\"Billiard table\":                  2,\n",
    "\"Microwave oven\":                  13,\n",
    "\"Refrigerator\":                    18,\n",
    "\"Fountain\":                        9,\n",
    "\"Gas stove\":                       10,\n",
    "\"Coffeemaker\":                     4,\n",
    "\"Bathtub\":                         0,\n",
    "\"Wine rack\":                       29,\n",
    "\"Jacuzzi\":                         11,\n",
    "\"Tree house\":                      27,\n",
    "\"Ceiling fan\":                     3,\n",
    "\"Shower\":                           19,\n",
    "\"Towel\":                            26,\n",
    "\"Dishwasher\":                       7}\n",
    "\n",
    "id_to_str = {str_to_id[string]:string for string in str_to_id}\n",
    "print(id_to_str)\n",
    "\n",
    "occurences = {\"Swimming pool\":                 161,\n",
    "\"Bed\":                            125,\n",
    "\"Pillow\":                          76,\n",
    "\"Kitchen & dining room table\":     76,\n",
    "\"Countertop\":                      68,\n",
    "\"Sofa bed\":                        61,\n",
    "\"Couch\":                           61,\n",
    "\"Sink\":                            57,\n",
    "\"Porch\":                           52,\n",
    "\"Stairs\":                          45,\n",
    "\"Television\":                      44,\n",
    "\"Fireplace\":                       41,\n",
    "\"Washing machine\":                 40,\n",
    "\"Toilet\":                          37,\n",
    "\"Oven\":                            36,\n",
    "\"Mirror\":                          33,\n",
    "\"Billiard table\":                  32,\n",
    "\"Microwave oven\":                  30,\n",
    "\"Refrigerator\":                    26,\n",
    "\"Fountain\":                        24,\n",
    "\"Gas stove\":                       23,\n",
    "\"Coffeemaker\":                     21,\n",
    "\"Bathtub\":                         18,\n",
    "\"Wine rack\":                       17,\n",
    "\"Jacuzzi\":                         16,\n",
    "\"Tree house\":                      11,\n",
    "\"Ceiling fan\":                     11,\n",
    "\"Shower\":                           9,\n",
    "\"Towel\":                            9,\n",
    "\"Dishwasher\":                       3}\n",
    "\n",
    "AP = {'Bathtub': 34.25027057569784,\n",
    "'Bed': 59.03879550756028,\n",
    "'Billiard table': 80.6170658008729,\n",
    "'Ceiling fan': 74.75247524752476,\n",
    "'Coffeemaker': 67.21489992445622,\n",
    "'Couch': 36.476634558768154,\n",
    "'Countertop': 12.059790879024206,\n",
    "'Dishwasher': 31.291378938099314,\n",
    "'Fireplace': 36.35683183029906,\n",
    "'Fountain': 41.94557512767471,\n",
    "'Gas stove': 18.65965580119998,\n",
    "'Jacuzzi': 28.651577645715214,\n",
    "'Kitchen & dining room table': 13.631045153528959,\n",
    "'Microwave oven': 53.651455417228014,\n",
    "'Mirror': 52.89604356333979,\n",
    "'Oven': 34.228370636894674,\n",
    "'Pillow': 18.82013126836111,\n",
    "'Porch': 15.723925102088343,\n",
    "'Refrigerator': 75.5005712805338,\n",
    "'Shower': 2.574831875856775,\n",
    "'Sink': 39.64110013165663,\n",
    "'Sofa bed': 63.42160711928795,\n",
    "'Stairs': 32.32828231466491,\n",
    "'Swimming pool': 74.7463747113812,\n",
    "'Television': 76.73849607919813,\n",
    "'Toilet': 47.50870541642443,\n",
    "'Towel': 32.80105970819099,\n",
    "'Tree house': 39.709301753070505,\n",
    "'Washing machine': 50.87204656214445,\n",
    "'Wine rack': 37.51794152757786}\n",
    "print(sum([AP[key] for key in AP]) / len(AP))\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for key in AP:\n",
    "    x.append(occurences[key])\n",
    "    y.append(AP[key])\n",
    "    \n",
    "from sklearn.metrics import r2_score \n",
    "print(\"Eval\")\n",
    "plt.title('AP Score by Size of Validation Set')\n",
    "plt.xlabel('# Examples')\n",
    "plt.ylabel('AP')\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "coef = np.corrcoef(x, y)[0, 1]\n",
    "print(coef)\n",
    "plt.text(115, 5, f'R^2 = {round(coef**2, 3)}', bbox=props, fontsize=14)\n",
    "# plt.annotate('Something', xy=(0.05, 0.95), xycoords='axes fraction')\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stairs                         5981\n",
    "Couch                          4259\n",
    "Swimming pool                  3881\n",
    "Porch                          3854\n",
    "Television                     3789\n",
    "Fountain                       3691\n",
    "Bed                            3563\n",
    "Pillow                         3508\n",
    "Countertop                     3113\n",
    "Kitchen & dining room table    2127\n",
    "Sink                           1648\n",
    "Mirror                         1572\n",
    "Sofa bed                       1501\n",
    "Toilet                         1099\n",
    "Billiard table                  912\n",
    "Fireplace                       711\n",
    "Washing machine                 655\n",
    "Oven                            637\n",
    "Refrigerator                    592\n",
    "Bathtub                         545\n",
    "Gas stove                       526\n",
    "Microwave oven                  485\n",
    "Ceiling fan                     478\n",
    "Towel                           338\n",
    "Coffeemaker                     323\n",
    "Wine rack                       254\n",
    "Shower                          235\n",
    "Tree house                      110\n",
    "Jacuzzi                         103\n",
    "Dishwasher                       92\"\"\"\n",
    "\n",
    "occurences = {\"Swimming pool\":                 3881,\n",
    "\"Bed\":                            3563,\n",
    "\"Pillow\":                          3508,\n",
    "\"Kitchen & dining room table\":     2127,\n",
    "\"Countertop\":                      3113,\n",
    "\"Sofa bed\":                        1501,\n",
    "\"Couch\":                           4259,\n",
    "\"Sink\":                            1648,\n",
    "\"Porch\":                           3854,\n",
    "\"Stairs\":                          5981,\n",
    "\"Television\":                      3789,\n",
    "\"Fireplace\":                       711,\n",
    "\"Washing machine\":                 655,\n",
    "\"Toilet\":                          1099,\n",
    "\"Oven\":                            637,\n",
    "\"Mirror\":                          1572,\n",
    "\"Billiard table\":                  912,\n",
    "\"Microwave oven\":                  485,\n",
    "\"Refrigerator\":                    592,\n",
    "\"Fountain\":                        3691,\n",
    "\"Gas stove\":                       526,\n",
    "\"Coffeemaker\":                     323,\n",
    "\"Bathtub\":                         545,\n",
    "\"Wine rack\":                       254,\n",
    "\"Jacuzzi\":                         103,\n",
    "\"Tree house\":                      110,\n",
    "\"Ceiling fan\":                     478,\n",
    "\"Shower\":                           235,\n",
    "\"Towel\":                            338,\n",
    "\"Dishwasher\":                       92}\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for key in AP:\n",
    "    x.append(occurences[key])\n",
    "    y.append(AP[key])\n",
    "    \n",
    "print(\"Test\")\n",
    "plt.title('AP Score by Size of Test Set')\n",
    "plt.xlabel('# Examples')\n",
    "plt.ylabel('AP')\n",
    "coef = np.corrcoef(x, y)[0, 1]\n",
    "print(coef)\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.text(4200, 5, f'R^2 = {round(coef**2, 3)}', bbox=props, fontsize=14)\n",
    "# plt.annotate('Something', xy=(0.05, 0.95), xycoords='axes fraction')\n",
    "plt.scatter(x, y)\n",
    "# print(np.corrcoef(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_thresh = 25.0\n",
    "poor_classes = set([str_to_id[key] for key in AP if AP[key] < min_thresh])\n",
    "poor_classes\n",
    "len(train_img_dicts)\n",
    "train_img_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_poor(img, poor_classes):\n",
    "    for box in img['annotations']:\n",
    "        if box['category_id'] in poor_classes:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "to_augment = [img for img in train_img_dicts if contains_poor(img, poor_classes)]\n",
    "len(to_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "\n",
    "aug_path = './aug/'\n",
    "\n",
    "def flipImages(images):\n",
    "    augmented_annotations = images\n",
    "    for i in range(len(images)):\n",
    "        im = Image.open(images[i]['file_name'])\n",
    "#         plt.imshow(cv2.imread(images[i][\"file_name\"]))\n",
    "#         plt.show()\n",
    "        out = im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        blur = out.filter(ImageFilter.GaussianBlur(3))\n",
    "        blur.save(aug_path + os.path.basename(images[i]['file_name']))\n",
    "#         plt.imshow(cv2.imread(aug_path + os.path.basename(images[i]['file_name'])))\n",
    "#         plt.show()\n",
    "#         break\n",
    "        w = images[i]['width']\n",
    "#         print(images[i]['annotations'])\n",
    "        for j in range(len(images[i]['annotations'])):\n",
    "            images[i]['annotations'][j]['bbox'][0] = w - images[i]['annotations'][j]['bbox'][0]\n",
    "            images[i]['annotations'][j]['bbox'][2] = w - images[i]['annotations'][j]['bbox'][2]\n",
    "#         print(images[i]['annotations'])\n",
    "    return augmented_annotations\n",
    "            \n",
    "augmented_annotations = flipImages(to_augment)\n",
    "with open('./output_aug/train_aug.json', \"w\") as f:\n",
    "      json.dump(augmented_annotations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'aug'\n",
    "DatasetCatalog.register(dataset_name, lambda dataset_name=dataset_name: load_json_labels(dataset_name))\n",
    "MetadataCatalog.get(dataset_name).set(thing_classes=target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "aug_cfg=get_cfg()\n",
    "aug_cfg.merge_from_file(\"./retinanet_model_final_config.yaml\")\n",
    "aug_cfg.MODEL.WEIGHTS = \"./retinanet_model_final.pth\"\n",
    "aug_cfg.DATASETS.TRAIN = (\"aug\",)\n",
    "aug_cfg.DATASETS.TEST = (\"validation\",)\n",
    "aug_cfg.OUTPUT_DIR = './output_aug/'\n",
    "aug_cfg.DATALOADER.NUM_WORKERS = 2\n",
    "aug_cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "aug_cfg.SOLVER.BASE_LR = 0.00125\n",
    "aug_cfg.SOLVER.MAX_ITER = 100\n",
    "aug_cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "aug_cfg.MODEL.RETINANET.NUM_CLASSES = len(target_classes)\n",
    "os.makedirs(aug_cfg.OUTPUT_DIR, exist_ok=True)\n",
    "aug_trainer = DefaultTrainer(aug_cfg)\n",
    "aug_trainer.resume_or_load(resume=False) \n",
    "aug_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_cfg.MODEL.WEIGHTS = os.path.join(aug_cfg.OUTPUT_DIR, \"model_final.pth\") \n",
    "aug_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2 \n",
    "aug_cfg.DATASETS.TEST = (\"validation\",) \n",
    "aug_predictor = DefaultPredictor(aug_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "aug_evaluator = COCOEvaluator(dataset_name=\"validation\", \n",
    "                          cfg=aug_cfg, \n",
    "                          distributed=False, \n",
    "                          output_dir=\"./output_aug/\")\n",
    "\n",
    "aug_val_loader = build_detection_test_loader(aug_cfg, \n",
    "                                         dataset_name=\"validation\")\n",
    "inference_on_dataset(model=aug_trainer.model, \n",
    "                     data_loader=aug_val_loader, \n",
    "                     evaluator=aug_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_inference2(\"bathroom.jpeg\",\n",
    "               model_config=\"./retinanet_model_final_config.yaml\",\n",
    "               model_weights=\"./retinanet_model_final.pth\",\n",
    "               n=3)\n",
    "make_inference(\"kitchen.jpeg\",\n",
    "               model_config=\"./retinanet_model_final_config.yaml\",\n",
    "               model_weights=\"./retinanet_model_final.pth\",\n",
    "               n=3)\n",
    "make_inference(\"bedroom.jpeg\",\n",
    "               model_config=\"./retinanet_model_final_config.yaml\",\n",
    "               model_weights=\"./retinanet_model_final.pth\",\n",
    "               n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_to_id\n",
    "kitchen= {'Coffeemaker', 'Countertop', 'Dishwasher', 'Gas stove', 'Kitchen & dining room table', 'Microwave oven', 'Microwave oven', 'Oven', 'Refrigerator', 'Sink', 'Wine rack'}\n",
    "bedroom = {'Bed', 'Pillow', 'Sofa bed', 'Television', 'Ceiling fan', 'Mirror'}\n",
    "living_room = {'Ceiling fan', 'Couch', 'Fireplace', 'Kitchen & dining room table', 'Pillow', 'Sofa bed', 'Television'}\n",
    "bathroom = {'Bathtub', 'Countertop', 'Mirror', 'Towel', 'Toilet'}\n",
    "outdoor = {'Fountain', 'Porch', 'Swimming pool', 'Tree house'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAP(room):\n",
    "    return sum([AP[amen] for amen in room]) / len(room)\n",
    "print(f\"The AP of the kitchen is {calcAP(kitchen)}\")\n",
    "print(f\"The AP of the bedroom is {calcAP(bedroom)}\")\n",
    "print(f\"The AP of the living room is {calcAP(living_room)}\")\n",
    "print(f\"The AP of the bathroom is {calcAP(bathroom)}\")\n",
    "print(f\"The AP of outdoor amenities is {calcAP(outdoor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference2(image, model_config, model_weights, threshold=0.5, n=5):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_config)\n",
    "    cfg.MODEL.WEIGHTS = model_weights\n",
    "    cfg.MODEL.SCORE_THRESH_TEST = threshold\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    img = cv2.imread(image)\n",
    "    visualizer = Visualizer(img_rgb=img[:, :, ::-1],\n",
    "                          metadata=MetadataCatalog.get(cfg.DATASETS.TEST[0]),\n",
    "                          scale=0.7)\n",
    "\n",
    "    outputs = predictor(img) \n",
    "    print(outputs['instances'])\n",
    "    instances = outputs['instances']\n",
    "#     dishwashers = instances[instances.pred_classes == 7]\n",
    "#     print(instances[instances.pred_classes == 7])\n",
    "    tables = instances[instances.pred_classes == 12]\n",
    "\n",
    "    visualizer = visualizer.draw_instance_predictions(tables.to(\"cpu\"))\n",
    "#         cv2_imshow(visualizer.get_image()[:, :, ::-1]) \n",
    "    pred_image = visualizer.get_image()[:, :, ::-1]\n",
    "    plt.figure(figsize = (20,20))\n",
    "    plt.imshow(pred_image)\n",
    "    plt.show()\n",
    "make_inference(\"kitchen.jpeg\",\n",
    "               model_config=\"./retinanet_model_final_config.yaml\",\n",
    "               model_weights=\"./retinanet_model_final.pth\",\n",
    "               n=3)\n",
    "make_inference2(\"kitchen.jpeg\",\n",
    "               model_config=\"./retinanet_model_final_config.yaml\",\n",
    "               model_weights=\"./retinanet_model_final.pth\",\n",
    "               n=3)\n",
    "id_to_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
